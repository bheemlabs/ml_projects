{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQE4BfqWtIzT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F7ZS6w13uLmZ"
   },
   "source": [
    "## Read from text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abt1VD3xuOdp"
   },
   "outputs": [],
   "source": [
    "# pd.read_csv({filename},sep={sep},encoding={encoding})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPCqLAgRuSe5"
   },
   "source": [
    "## Read from relational database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a36nbCYIuVri"
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "# create a connection object 'conn'\n",
    "conn = pymysql.connect(host = \"localhost\",\n",
    "                      user=\"root\",\n",
    "                      passwd=\"12345\",\n",
    "                      db=\"information_schema\")\n",
    "\n",
    "# create a cursor object c\n",
    "c = conn.cursor()\n",
    "\n",
    "# execute query using c.execute\n",
    "c.execute(\"select * from engines;\")\n",
    "\n",
    "# getting the first row of data as a tuple\n",
    "all_rows = c.fetchall()\n",
    "\n",
    "# to get only the first row, use c.fetchone() instead\n",
    "\n",
    "\n",
    "df = pd.DataFrame(list(all_rows), columns=[\"engine\", \"support\", \"comment\", \n",
    "                                           \"transactions\", \"XA\", \"savepoints\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-pzBtI7Dynsp"
   },
   "source": [
    "## Read from websites - Website scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7xvWpm3ymKK"
   },
   "outputs": [],
   "source": [
    "# 'BeautifulSoup' library is used to parse HTML files \n",
    "import requests, bs4\n",
    "\n",
    "# getting HTML data from the Google play web page\n",
    "url = \"https://play.google.com/store/apps/details?id=com.facebook.orca&hl=en\"\n",
    "req = requests.get(url)\n",
    "\n",
    "# create a bs4 object\n",
    "# To avoid warnings, provide \"html5lib\" explicitly\n",
    "soup = bs4.BeautifulSoup(req.text, \"html5lib\")\n",
    "#print(soup)\n",
    "\n",
    "# getting all the text inside class = \"review-body\"\n",
    "reviews = soup.select('.review-body')\n",
    "print(type(reviews))\n",
    "print(len(reviews))\n",
    "print(\"\\n\")\n",
    "\n",
    "# printing an element of the reviews list\n",
    "print(reviews[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EGeHeAqH3IzB"
   },
   "source": [
    "## Read from APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pd5B5UTA3L2w"
   },
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "# Make the request with the coordinates of San Francisco.\n",
    "parameters = {\"lat\": 37.78, \"lon\": -122.41}\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\", params=parameters)\n",
    "\n",
    "# Get the response data as a python object.  Verify that it's a dictionary.\n",
    "data = response.json()\n",
    "print(type(data))\n",
    "print(data)\n",
    "\n",
    "print(response.headers)\n",
    "print(response.headers[\"content-type\"])\n",
    "\n",
    "\n",
    "# Get the response from the API endpoint.\n",
    "response = requests.get(\"http://api.open-notify.org/astros.json\")\n",
    "data = response.json()\n",
    "\n",
    "# 9 people are currently in space.\n",
    "print(data[\"number\"])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOA1-0I17X2w"
   },
   "source": [
    "## Reading data from PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9eJEC99a7aq_"
   },
   "outputs": [],
   "source": [
    "import pyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVWT_w2V_PvP"
   },
   "source": [
    "# Mounting Google Drive locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZvzKJ0g_R9g"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSUQSaa88K9A"
   },
   "source": [
    "# Cleaning datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f31F_WlM8POP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/melbourne.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XL3m_EXjAX8g"
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bko9D5IAuQf"
   },
   "outputs": [],
   "source": [
    "df.isnull()\n",
    "\n",
    "# summing up the missing values (column-wise)\n",
    "df.isnull().sum()\n",
    "\n",
    "# columns having at least one missing value\n",
    "df.isnull().any()\n",
    "\n",
    "# above is equivalent to axis=0 (by default, any() operates on columns)\n",
    "df.isnull().any(axis=0) #axis=0 => column-wise, axis=1 => row-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YTAq95NWDxIG"
   },
   "outputs": [],
   "source": [
    "# check if rows which have all values missing\n",
    "df.isnull().all(axis=1)\n",
    "df.isnull().all(axis=1).sum() # 0 => There are no rows with all column values missing\n",
    "\n",
    "# sum of missing values in each row\n",
    "df.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9msE3Y1EoiG"
   },
   "source": [
    "## Treat missing values\n",
    "\n",
    "\n",
    "1.   Do nothing if algorithm doesn't complaing about missing values\n",
    "2.   Delete them\n",
    "3.   Replace with value such as Mean, median, mode, etc. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRYPB4nmErZm"
   },
   "outputs": [],
   "source": [
    "# Summing up the missing values (column-wise) %\n",
    "round(100*(df.isnull().sum()/len(df.index)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMFXSE9TF-Lu"
   },
   "outputs": [],
   "source": [
    "# remove columns with more than 30% missing values\n",
    "df = df.drop('BuildingArea', axis=1)\n",
    "df = df.drop('YearBuilt', axis=1)\n",
    "df = df.drop('CouncilArea', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLz6GJBzGX4m"
   },
   "outputs": [],
   "source": [
    " # Summing up the missing values (column-wise) %\n",
    "round(100*(df.isnull().sum()/len(df.index)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNZsJRJ7NaU-"
   },
   "outputs": [],
   "source": [
    "# check rows with more than 5 missing values\n",
    "df[df.isnull().sum(axis=1) > 5]\n",
    "len(df[df.isnull().sum(axis=1) > 5].index)\n",
    "100*(len(df[df.isnull().sum(axis=1) > 5].index)/len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOasxSiyOBx1"
   },
   "outputs": [],
   "source": [
    "# remove rows with more than 5 missing values\n",
    "df = df[df.isnull().sum(axis=1) <= 5]\n",
    "\n",
    " # Summing up the missing values (column-wise) %\n",
    "round(100*(df.isnull().sum()/len(df.index)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqg7WVkyOkEl"
   },
   "outputs": [],
   "source": [
    "# remove rows with Price null\n",
    "df = df[~np.isnan(df['Price'])]\n",
    "\n",
    " # Summing up the missing values (column-wise) %\n",
    "round(100*(df.isnull().sum()/len(df.index)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJiBgT3XPOLV"
   },
   "outputs": [],
   "source": [
    "# check Landsize column and try to impute values for this column\n",
    "df['Landsize'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2HAKxzmUPZ29"
   },
   "source": [
    "Notice that min is 0, max is 433014, the mean is 558, median (50%) is 440. There's a significant variation in the 25th and 75th percentile as well. (176 to 651)\n",
    "\n",
    "Thus imputing this with mean/median seems quite biased, and so we should remove the NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ft4wsxpPWmV"
   },
   "outputs": [],
   "source": [
    "# removing NaNs in Landsize\n",
    "df = df[~np.isnan(df['Landsize'])]\n",
    "\n",
    " # Summing up the missing values (column-wise) %\n",
    "round(100*(df.isnull().sum()/len(df.index)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pvnBbCdhQbpW"
   },
   "source": [
    "There's still marginal data with missing values. Bathroom, Car, Latitude, Longitude. Let's first look at Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtXhurXNQbFV"
   },
   "outputs": [],
   "source": [
    "# rows with missing Latitude, Longitude\n",
    "df[np.isnan(df['Lattitude'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_YyWZKUhQ8er"
   },
   "outputs": [],
   "source": [
    "# Let's look at the summary stats of Latitude/Longitude columns\n",
    "df.loc[:,['Lattitude','Longtitude']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rdq3wrPGRhMN"
   },
   "source": [
    "Since, Std deviation is very small, we can impute these missing values with mean of corresponding columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DOL82AveRo6V"
   },
   "outputs": [],
   "source": [
    "# imputing Lattitude and Longtitude by mean values\n",
    "df.loc[np.isnan(df['Lattitude']), ['Lattitude']] = df['Lattitude'].mean()\n",
    "df.loc[np.isnan(df['Longtitude']), ['Longtitude']] = df['Longtitude'].mean()\n",
    "\n",
    " # Summing up the missing values (column-wise) %\n",
    "round(100*(df.isnull().sum()/len(df.index)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OP4w6KU7SJGE"
   },
   "source": [
    "We have Bathroom, Car have missing values with 0.01% and 0.46%. Let's look at the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsxwWinJSSfI"
   },
   "outputs": [],
   "source": [
    "df.loc[:, ['Bathroom','Car']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KLJdW1DlSmVp"
   },
   "source": [
    "These 2 are integer type variables and thus have values 0, 1, 2, etc. You cannot impute the NaNs by mean or median. Thus, you need to impute them by the mode - the most common occuring value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jec_FYBoS0Ps"
   },
   "outputs": [],
   "source": [
    "# converting to type'category\n",
    "df['Car']  = df['Car'].astype('category')\n",
    "\n",
    "# displaying frequencies of each category\n",
    "df['Car'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6I4pzsszTGI7"
   },
   "outputs": [],
   "source": [
    "# the most common occuring is 2, so let's impute NaNs by that. \n",
    "\n",
    "#imputing NaNs by 2.0\n",
    "df.loc[pd.isnull(df['Car']), ['Car']] = 2\n",
    "\n",
    " # Summing up the missing values (column-wise) %\n",
    "round(100*(df.isnull().sum()/len(df.index)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYi0OwBXTtRJ"
   },
   "outputs": [],
   "source": [
    "# Similar to Bathroom\n",
    "\n",
    "df['Bathroom'] = df['Bathroom'].astype('category')\n",
    "\n",
    "df['Bathroom'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6MdstUaT850"
   },
   "outputs": [],
   "source": [
    "df.loc[pd.isnull(df['Bathroom']),['Bathroom']] = 1\n",
    "\n",
    " # Summing up the missing values (column-wise) %\n",
    "round(100*(df.isnull().sum()/len(df.index)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ph2RM98aULrI"
   },
   "source": [
    "There are no missing values now. Let's finally look at how many rows (apart from 3 columns) we have lost in the process(originally we had 23547):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_VfoM57ZUbyT"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBMFIEmZUeFm"
   },
   "outputs": [],
   "source": [
    "100 * (len(df.index)/23547)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gH4FuBQWUkRB"
   },
   "source": [
    "Thus we have lost about 42% of observations in cleaning the missing values. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2. Getting_Cleaning_Data.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
