{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Getting_Cleaning_Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "pQE4BfqWtIzT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F7ZS6w13uLmZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read from text files"
      ]
    },
    {
      "metadata": {
        "id": "abt1VD3xuOdp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pd.read_csv({filename},sep={sep},encoding={encoding})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iPCqLAgRuSe5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read from relational database"
      ]
    },
    {
      "metadata": {
        "id": "a36nbCYIuVri",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pymysql\n",
        "\n",
        "# create a connection object 'conn'\n",
        "conn = pymysql.connect(host = \"localhost\",\n",
        "                      user=\"root\",\n",
        "                      passwd=\"12345\",\n",
        "                      db=\"information_schema\")\n",
        "\n",
        "# create a cursor object c\n",
        "c = conn.cursor()\n",
        "\n",
        "# execute query using c.execute\n",
        "c.execute(\"select * from engines;\")\n",
        "\n",
        "# getting the first row of data as a tuple\n",
        "all_rows = c.fetchall()\n",
        "\n",
        "# to get only the first row, use c.fetchone() instead\n",
        "\n",
        "\n",
        "df = pd.DataFrame(list(all_rows), columns=[\"engine\", \"support\", \"comment\", \n",
        "                                           \"transactions\", \"XA\", \"savepoints\"])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-pzBtI7Dynsp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read from websites - Website scrapping"
      ]
    },
    {
      "metadata": {
        "id": "a7xvWpm3ymKK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 'BeautifulSoup' library is used to parse HTML files \n",
        "import requests, bs4\n",
        "\n",
        "# getting HTML data from the Google play web page\n",
        "url = \"https://play.google.com/store/apps/details?id=com.facebook.orca&hl=en\"\n",
        "req = requests.get(url)\n",
        "\n",
        "# create a bs4 object\n",
        "# To avoid warnings, provide \"html5lib\" explicitly\n",
        "soup = bs4.BeautifulSoup(req.text, \"html5lib\")\n",
        "#print(soup)\n",
        "\n",
        "# getting all the text inside class = \"review-body\"\n",
        "reviews = soup.select('.review-body')\n",
        "print(type(reviews))\n",
        "print(len(reviews))\n",
        "print(\"\\n\")\n",
        "\n",
        "# printing an element of the reviews list\n",
        "print(reviews[6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EGeHeAqH3IzB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read from APIs"
      ]
    },
    {
      "metadata": {
        "id": "pd5B5UTA3L2w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests, json\n",
        "\n",
        "# Make the request with the coordinates of San Francisco.\n",
        "parameters = {\"lat\": 37.78, \"lon\": -122.41}\n",
        "response = requests.get(\"http://api.open-notify.org/iss-pass.json\", params=parameters)\n",
        "\n",
        "# Get the response data as a python object.  Verify that it's a dictionary.\n",
        "data = response.json()\n",
        "print(type(data))\n",
        "print(data)\n",
        "\n",
        "print(response.headers)\n",
        "print(response.headers[\"content-type\"])\n",
        "\n",
        "\n",
        "# Get the response from the API endpoint.\n",
        "response = requests.get(\"http://api.open-notify.org/astros.json\")\n",
        "data = response.json()\n",
        "\n",
        "# 9 people are currently in space.\n",
        "print(data[\"number\"])\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TOA1-0I17X2w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading data from PDF files"
      ]
    },
    {
      "metadata": {
        "id": "9eJEC99a7aq_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pyPDF2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVWT_w2V_PvP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mounting Google Drive locally"
      ]
    },
    {
      "metadata": {
        "id": "QZvzKJ0g_R9g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LSUQSaa88K9A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Cleaning datasets"
      ]
    },
    {
      "metadata": {
        "id": "f31F_WlM8POP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/melbourne.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XL3m_EXjAX8g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print(df.info())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_bko9D5IAuQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.isnull()\n",
        "\n",
        "# summing up the missing values (column-wise)\n",
        "df.isnull().sum()\n",
        "\n",
        "# columns having at least one missing value\n",
        "df.isnull().any()\n",
        "\n",
        "# above is equivalent to axis=0 (by default, any() operates on columns)\n",
        "df.isnull().any(axis=0) #axis=0 => column-wise, axis=1 => row-wise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YTAq95NWDxIG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check if rows which have all values missing\n",
        "df.isnull().all(axis=1)\n",
        "df.isnull().all(axis=1).sum() # 0 => There are no rows with all column values missing\n",
        "\n",
        "# sum of missing values in each row\n",
        "df.isnull().sum(axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m9msE3Y1EoiG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Treat missing values\n",
        "\n",
        "\n",
        "1.   Do nothing if algorithm doesn't complaing about missing values\n",
        "2.   Delete them\n",
        "3.   Replace with value such as Mean, median, mode, etc. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BRYPB4nmErZm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Summing up the missing values (column-wise) %\n",
        "round(100*(df.isnull().sum()/len(df.index)),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YMFXSE9TF-Lu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove columns with more than 30% missing values\n",
        "df = df.drop('BuildingArea', axis=1)\n",
        "df = df.drop('YearBuilt', axis=1)\n",
        "df = df.drop('CouncilArea', axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wLz6GJBzGX4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " # Summing up the missing values (column-wise) %\n",
        "round(100*(df.isnull().sum()/len(df.index)),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pNZsJRJ7NaU-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check rows with more than 5 missing values\n",
        "df[df.isnull().sum(axis=1) > 5]\n",
        "len(df[df.isnull().sum(axis=1) > 5].index)\n",
        "100*(len(df[df.isnull().sum(axis=1) > 5].index)/len(df.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nOasxSiyOBx1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove rows with more than 5 missing values\n",
        "df = df[df.isnull().sum(axis=1) <= 5]\n",
        "\n",
        " # Summing up the missing values (column-wise) %\n",
        "round(100*(df.isnull().sum()/len(df.index)),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wqg7WVkyOkEl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove rows with Price null\n",
        "df = df[~np.isnan(df['Price'])]\n",
        "\n",
        " # Summing up the missing values (column-wise) %\n",
        "round(100*(df.isnull().sum()/len(df.index)),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VJiBgT3XPOLV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check Landsize column and try to impute values for this column\n",
        "df['Landsize'].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2HAKxzmUPZ29",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that min is 0, max is 433014, the mean is 558, median (50%) is 440. There's a significant variation in the 25th and 75th percentile as well. (176 to 651)\n",
        "\n",
        "Thus imputing this with mean/median seems quite biased, and so we should remove the NaNs."
      ]
    },
    {
      "metadata": {
        "id": "6ft4wsxpPWmV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# removing NaNs in Landsize\n",
        "df = df[~np.isnan(df['Landsize'])]\n",
        "\n",
        " # Summing up the missing values (column-wise) %\n",
        "round(100*(df.isnull().sum()/len(df.index)),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pvnBbCdhQbpW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There's still marginal data with missing values. Bathroom, Car, Latitude, Longitude. Let's first look at Latitude and Longitude"
      ]
    },
    {
      "metadata": {
        "id": "AtXhurXNQbFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# rows with missing Latitude, Longitude\n",
        "df[np.isnan(df['Lattitude'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_YyWZKUhQ8er",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's look at the summary stats of Latitude/Longitude columns\n",
        "df.loc[:,['Lattitude','Longtitude']].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rdq3wrPGRhMN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since, Std deviation is very small, we can impute these missing values with mean of corresponding columns. "
      ]
    },
    {
      "metadata": {
        "id": "DOL82AveRo6V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# imputing Lattitude and Longtitude by mean values\n",
        "df.loc[np.isnan(df['Lattitude']), ['Lattitude']] = df['Lattitude'].mean()\n",
        "df.loc[np.isnan(df['Longtitude']), ['Longtitude']] = df['Longtitude'].mean()\n",
        "\n",
        " # Summing up the missing values (column-wise) %\n",
        "round(100*(df.isnull().sum()/len(df.index)),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OP4w6KU7SJGE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have Bathroom, Car have missing values with 0.01% and 0.46%. Let's look at the statistics"
      ]
    },
    {
      "metadata": {
        "id": "ZsxwWinJSSfI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.loc[:, ['Bathroom','Car']].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLJdW1DlSmVp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These 2 are integer type variables and thus have values 0, 1, 2, etc. You cannot impute the NaNs by mean or median. Thus, you need to impute them by the mode - the most common occuring value"
      ]
    },
    {
      "metadata": {
        "id": "jec_FYBoS0Ps",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting to type'category\n",
        "df['Car']  = df['Car'].astype('category')\n",
        "\n",
        "# displaying frequencies of each category\n",
        "df['Car'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6I4pzsszTGI7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the most common occuring is 2, so let's impute NaNs by that. \n",
        "\n",
        "#imputing NaNs by 2.0\n",
        "df.loc[pd.isnull(df['Car']), ['Car']] = 2\n",
        "\n",
        " # Summing up the missing values (column-wise) %\n",
        "round(100*(df.isnull().sum()/len(df.index)),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UYi0OwBXTtRJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Similar to Bathroom\n",
        "\n",
        "df['Bathroom'] = df['Bathroom'].astype('category')\n",
        "\n",
        "df['Bathroom'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6MdstUaT850",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.loc[pd.isnull(df['Bathroom']),['Bathroom']] = 1\n",
        "\n",
        " # Summing up the missing values (column-wise) %\n",
        "round(100*(df.isnull().sum()/len(df.index)),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ph2RM98aULrI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are no missing values now. Let's finally look at how many rows (apart from 3 columns) we have lost in the process(originally we had 23547):"
      ]
    },
    {
      "metadata": {
        "id": "_VfoM57ZUbyT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mBMFIEmZUeFm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "100 * (len(df.index)/23547)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gH4FuBQWUkRB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Thus we have lost about 42% of observations in cleaning the missing values. "
      ]
    }
  ]
}